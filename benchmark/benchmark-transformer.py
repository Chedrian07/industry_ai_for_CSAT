from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer
import json
import re
import argparse
from tqdm import tqdm
import torch

# ------- Default Model Settings for Transformers ------- # 
model_name = "./fused_model" 
#model_name = "LGAI-EXAONE/EXAONE-4.0-1.2B"

# Load fused model (already contains adapter weights)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,  # Set to bf16
    device_map="auto",
    low_cpu_mem_usage=True
)

tokenizer = AutoTokenizer.from_pretrained(model_name)

def load_dataset(file_path):
    """JSON íŒŒì¼ì—ì„œ ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ì—°ë„ë³„ë¡œ ê·¸ë£¹í™” ë° íŒŒì‹±í•©ë‹ˆë‹¤."""
    with open(file_path, 'r', encoding='utf-8') as f:
        problems = json.load(f)
    
    yearly_data = {}
    option_map = {'â‘ ': 1, 'â‘¡': 2, 'â‘¢': 3, 'â‘£': 4, 'â‘¤': 5}

    for problem in problems:
        try:
            # EXAM_NAMEì—ì„œ ì—°ë„ ì •ë³´ ì¶”ì¶œ
            match = re.search(r'(\d{4})', problem.get('EXAM_NAME', ''))
            if not match:
                continue
            
            year = int(match.group(1))
            if year not in yearly_data:
                yearly_data[year] = {'year': year, 'problems': []}
            
            # ì ìˆ˜ íŒŒì‹±
            score = 3 if '[3ì ]' in problem.get('question', '') else 2

            # ì»¨í…ìŠ¤íŠ¸ì™€ ë³´ê¸°(stimulus_box)ë¥¼ ì§ˆë¬¸ì— í¬í•¨
            full_question_text = ""
            if problem.get('context'):
                full_question_text += problem['context'] + "\n\n"
            
            if problem.get('stimulus_box') and isinstance(problem['stimulus_box'], dict):
                stimulus_text = "\n".join([f"{key}. {value}" for key, value in problem['stimulus_box'].items()])
                if stimulus_text:
                    full_question_text += "<ë³´ê¸°>\n" + stimulus_text + "\n\n"
            
            full_question_text += problem.get('question', '')

            # ì„ íƒì§€ íŒŒì‹±
            options_list = []
            options_dict = problem.get('options', {})
            if isinstance(options_dict, dict):
                # í‚¤ ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ option_map ìˆœì„œëŒ€ë¡œ ì •ë ¬
                sorted_keys = sorted(options_dict.keys(), key=lambda k: list(option_map.keys()).index(k) if k in option_map else 99)
                options_list = [options_dict[key] for key in sorted_keys]

            # ì •ë‹µ íŒŒì‹±
            answer_key = problem.get('answer', {}).get('correct_option')
            answer = option_map.get(answer_key)

            if answer is None:
                continue

            yearly_data[year]['problems'].append({
                'id': problem.get('id', 'N/A'),
                'question': full_question_text,
                'options': options_list,
                'answer': answer,
                'score': score
            })

        except Exception as e:
            print(f"ê²½ê³ : ë¬¸ì œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ê±´ë„ˆëœë‹ˆë‹¤. ì˜¤ë¥˜: {e}, ë¬¸ì œ ID: {problem.get('id')}")
            continue
    
    return sorted(yearly_data.values(), key=lambda x: x['year'])

def get_model_answer(prompt):
    system_prompt = """ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ìˆ˜ëŠ¥ ì§ì—…íƒêµ¬ ì˜ì—­ 'ê³µì—… ì¼ë°˜' ê³¼ëª©ì— ì •í†µí•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë¬¸ì œë¥¼ ì‹ ì¤‘íˆ ë¶„ì„í•˜ê³ , ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

{
    "ì •ë‹µ": ì •ë‹µë²ˆí˜¸,
    "í•´ì„¤": ë¬¸ì œí•´ì„¤
}

ì •ë‹µì€ ë°˜ë“œì‹œ 1, 2, 3, 4, 5 ì¤‘ í•˜ë‚˜ì˜ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤."""

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt}
    ]
    
    # Enable reasoning mode with enable_thinking=True
    input_ids = tokenizer.apply_chat_template(
        messages,
        tokenize=True,
        add_generation_prompt=True,
        return_tensors="pt",
        presence_penalty=1.5,
        enable_thinking=True
    )

    # Create streamer to show reasoning process
    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)
    
    print("\nğŸ¤” ëª¨ë¸ ì‚¬ê³  ê³¼ì •:")
    print("-" * 60)
    
    # Generate with reasoning parameters and streaming
    output = model.generate(
        input_ids.to(model.device),
        max_new_tokens=12000,
        do_sample=True,
        temperature=0.65,
        top_p=0.95,
        streamer=streamer
    )
    
    print("-" * 60)
    
    response = tokenizer.decode(output[0], skip_special_tokens=False)
    
    # Remove the input from the response to get only the generated part
    prompt_text = tokenizer.decode(input_ids[0], skip_special_tokens=False)
    if response.startswith(prompt_text):
        response = response[len(prompt_text):].strip()
    
    return response

def extract_answer(text):
    """ëª¨ë¸ì˜ JSON ì‘ë‹µì—ì„œ ì •ë‹µ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        # Extract content after </think> tag (the final answer)
        think_pattern = r'</think>(.*?)$'
        think_match = re.search(think_pattern, text, re.DOTALL)
        if think_match:
            final_response = think_match.group(1).strip()
        else:
            final_response = text
        
        # 1. ê°€ì¥ ë§ˆì§€ë§‰ì— ë‚˜íƒ€ë‚˜ëŠ” JSON ë¸”ë¡ì„ íŒŒì‹± (ê°€ì¥ ê°€ëŠ¥ì„± ë†’ì€ ìµœì¢… ë‹µë³€)
        try:
            json_matches = re.findall(r'\{[^{}]*\}', final_response, re.DOTALL)
            if json_matches:
                # ê°€ì¥ ë§ˆì§€ë§‰ JSON ë¸”ë¡ì„ ì‚¬ìš©
                json_str = json_matches[-1]
                data = json.loads(json_str)
                if "ì •ë‹µ" in data and str(data["ì •ë‹µ"]).isdigit() and 1 <= int(data["ì •ë‹µ"]) <= 5:
                    return int(data["ì •ë‹µ"])
        except (json.JSONDecodeError, ValueError):
            pass

        # 2. 'ì •ë‹µ' í‚¤ì›Œë“œì™€ í•¨ê»˜ ëª…ì‹œëœ ìˆ«ì ì¶”ì¶œ (ê°€ì¥ ë§ˆì§€ë§‰ ë§¤ì¹­)
        # ì˜ˆ: "ì •ë‹µ": 3, ì •ë‹µ: 3, ì •ë‹µì€ 3
        answer_patterns = [
            r'"ì •ë‹µ"\s*:\s*"?([1-5])"?',
            r'ì •ë‹µì€?\s*[:\s]*([1-5])'
        ]
        
        best_match = None
        for pattern in answer_patterns:
            matches = list(re.finditer(pattern, final_response))
            if matches:
                best_match = matches[-1] # ê°€ì¥ ë§ˆì§€ë§‰ ë§¤ì¹­ ì‚¬ìš©
        
        if best_match:
            return int(best_match.group(1))

        # 3. ë¬¸ë§¥ì—ì„œ ë²—ì–´ë‚œ ë‹¨ì¼ ìˆ«ì ì¶”ì¶œ
        # ëª¨ë¸ì´ ìˆ«ìë§Œ ë©ê·¸ëŸ¬ë‹ˆ ë°˜í™˜í•˜ëŠ” ê²½ìš°
        final_numbers = re.findall(r'^\s*([1-5])\s*$', final_response, re.MULTILINE)
        if final_numbers:
            return int(final_numbers[-1])

    except (ValueError, TypeError):
        pass
    
    return None

def solve_and_grade(yearly_data, debug=False):
    """ì—°ë„ë³„ ë¬¸ì œë¥¼ í’€ê³  ì±„ì í•©ë‹ˆë‹¤."""
    total_score = 0
    correct_count = 0
    total_questions = len(yearly_data['problems'])
    
    # ë¡œê·¸ íŒŒì¼ ì´ˆê¸°í™”
    with open('./log.txt', 'w', encoding='utf-8') as log_file:
        log_file.write(f"===== {yearly_data['year']}ë…„ë„ ì˜¤ë‹µ ë° ì˜¤ë¥˜ ë¡œê·¸ =====\n\n")
    
    print(f"\n===== {yearly_data['year']}ë…„ë„ ë¬¸ì œ í’€ì´ ì‹œì‘ =====")
    
    # ë””ë²„ê·¸ ëª¨ë“œì—ì„œëŠ” tqdmì„ ë¹„í™œì„±í™”í•©ë‹ˆë‹¤.
    if debug:
        problems_iter = yearly_data['problems']
    else:
        problems_iter = tqdm(yearly_data['problems'], desc=f"{yearly_data['year']}ë…„ë„ ì§„í–‰ë¥ ")
    
    for i, problem in enumerate(problems_iter, 1):
        question_text = problem['question']
        if problem.get('options'):
            options_text = "\n".join([f"{i+1}. {opt}" for i, opt in enumerate(problem['options'])])
            question_text += "\n" + options_text
        
        prompt = f"ë‹¤ìŒ ë¬¸ì œë¥¼ ì‹ ì¤‘íˆ ë¶„ì„í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n\n{question_text}"
        
        model_response = get_model_answer(prompt)
        model_answer = extract_answer(model_response)
        correct_answer = problem['answer']

        is_correct = model_answer == correct_answer
        if is_correct:
            total_score += problem['score']
            correct_count += 1

        # ì‹¤ì‹œê°„ ì±„ì  ê²°ê³¼ ì¶œë ¥ (ë””ë²„ê·¸ ëª¨ë“œê°€ ì•„ë‹ ë•Œë„)
        result_symbol = "âœ“" if is_correct else "âœ—"
        print(f"ë¬¸ì œ {i:2d}/{total_questions} [{problem['id']}]: {result_symbol} (ëª¨ë¸ë‹µ: {model_answer}, ì •ë‹µ: {correct_answer}) | í˜„ì¬ ì ìˆ˜: {total_score}/50ì  (ì •ë‹µë¥ : {correct_count}/{i}, {correct_count/i*100:.1f}%)")

        # ì˜¤ë‹µì´ê±°ë‚˜ ëª¨ë¸ë‹µì´ Noneì¸ ê²½ìš° ë¡œê·¸ì— ê¸°ë¡
        if not is_correct or model_answer is None:
            with open('./log.txt', 'a', encoding='utf-8') as log_file:
                log_file.write(f"--- ë¬¸ì œ {i} [{problem['id']}] ---\n")
                log_file.write(f"ìƒíƒœ: {'íŒŒì‹± ì‹¤íŒ¨' if model_answer is None else 'ì˜¤ë‹µ'}\n")
                log_file.write(f"ëª¨ë¸ ë‹µ: {model_answer}\n")
                log_file.write(f"ì •ë‹µ: {correct_answer}\n")
                log_file.write(f"ë¬¸ì œ:\n{question_text}\n\n")
                log_file.write(f"ëª¨ë¸ ì‘ë‹µ:\n{model_response}\n")
                log_file.write("="*80 + "\n\n")

        if debug:
            print(f"\n--- ë¬¸ì œ {problem['id']} ìƒì„¸ ---")
            print(f"ë¬¸ì œ:\n{question_text}")
            print(f"ëª¨ë¸ ì‘ë‹µ: {model_response}")
            print(f"ëª¨ë¸ ì¶”ì¶œ ë‹µ: {model_answer}, ì •ë‹µ: {correct_answer}")
            print(f"ì±„ì  ê²°ê³¼: {'ì •ë‹µ' if is_correct else 'ì˜¤ë‹µ'} (ì ìˆ˜: {problem['score'] if is_correct else 0})")
            input("ê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

    print(f"\n===== {yearly_data['year']}ë…„ë„ ìµœì¢… ì±„ì  ê²°ê³¼ =====")
    print(f"ì´ {total_questions}ë¬¸ì œ ì¤‘ {correct_count}ë¬¸ì œ ì •ë‹µ ({correct_count/total_questions*100:.1f}%)")
    print(f"ì´ì : {total_score}ì  / 50ì  ë§Œì  ({total_score/50*100:.1f}%)")
    print(f"ì˜¤ë‹µ ë° ì˜¤ë¥˜ ë¡œê·¸ê°€ './log.txt'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return total_score

def main():
    parser = argparse.ArgumentParser(description="CSAT ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œë¥¼ í™œì„±í™”í•˜ì—¬ ë¬¸ì œë³„ ì§„í–‰ ìƒí™©ê³¼ ëª¨ë¸ ì‘ë‹µì„ í™•ì¸í•©ë‹ˆë‹¤.')
    args = parser.parse_args()

    dataset = load_dataset('benchmark/full_csat_dataset.json')
    
    # 2025ë…„ ë°ì´í„°ë§Œ í•„í„°ë§í•˜ì—¬ ì‹¤í–‰
    found_2025 = False
    for year_data in dataset:
        # 'year' í‚¤ì˜ ê°’ì´ ë¬¸ìì—´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ intë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµí•©ë‹ˆë‹¤.
        if int(year_data.get('year', 0)) == 2025:
            solve_and_grade(year_data, debug=args.debug)
            found_2025 = True
            break
    
    if not found_2025:
        print("2025ë…„ë„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
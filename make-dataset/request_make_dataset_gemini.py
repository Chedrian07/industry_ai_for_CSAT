import os
import json
import glob
import time
import re
from pathlib import Path
from datetime import datetime
import google.generativeai as genai
from PIL import Image
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GeminiDatasetCreator:
    def __init__(self):
        """Gemini APIë¥¼ ì‚¬ìš©í•œ ë°ì´í„°ì…‹ ìƒì„±ê¸° ì´ˆê¸°í™”"""
        self.setup_gemini()
        self.base_dir = Path(__file__).parent
        self.images_dir = self.base_dir / "images"
        self.output_dir = self.base_dir / "gemini_responses"
        self.output_dir.mkdir(exist_ok=True)
        
        # ë£¨íŠ¸ì˜ ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ
        self.reference_image = self.load_reference_image()
        
    def setup_gemini(self):
        """Gemini API ì„¤ì •"""
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        genai.configure(api_key=api_key)
        self.model = genai.GenerativeModel('gemini-2.5-flash')
        logger.info("âœ… Gemini API ì„¤ì • ì™„ë£Œ")
    
    def load_reference_image(self):
        """ë£¨íŠ¸ì— ìˆëŠ” ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ"""
        reference_path = self.images_dir / "page_001.png"
        
        if not reference_path.exists():
            logger.warning(f"âš ï¸  ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {reference_path}")
            return None
        
        try:
            reference_image = Image.open(reference_path)
            logger.info(f"ğŸ“‹ ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ: {reference_path.name}")
            return reference_image
        except Exception as e:
            logger.error(f"âŒ ì°¸ì¡° ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def get_processing_order(self):
        """ì²˜ë¦¬í•  ë””ë ‰í† ë¦¬ë“¤ì˜ ìˆœì„œ ê²°ì •"""
        processing_order = []
        
        # 1. Chapter ë””ë ‰í† ë¦¬ë“¤ (1-20 ìˆœì„œë¡œ, ê° ì±•í„°ë§ˆë‹¤ ì¼ë°˜->test ìˆœ)
        for i in range(1, 21):
            chapter_dir = f"Chapter_{i}"
            chapter_test_dir = f"Chapter_{i}_test"
            
            if (self.images_dir / chapter_dir).exists():
                processing_order.append(chapter_dir)
            if (self.images_dir / chapter_test_dir).exists():
                processing_order.append(chapter_test_dir)
        
        # 2. CSAT_EXAM ë””ë ‰í† ë¦¬ë“¤ (ì—°ë„_ì›” ìˆœì„œë¡œ ì •ë ¬)
        csat_pattern = re.compile(r'(\d{2})_(\d{2})_CSAT_EXAM')
        csat_dirs = []
        
        for item in self.images_dir.iterdir():
            if item.is_dir() and csat_pattern.match(item.name):
                match = csat_pattern.match(item.name)
                year = int(match.group(1))
                month = int(match.group(2))
                csat_dirs.append((year, month, item.name))
        
        # ì—°ë„, ì›” ìˆœìœ¼ë¡œ ì •ë ¬
        csat_dirs.sort(key=lambda x: (x[0], x[1]))
        processing_order.extend([item[2] for item in csat_dirs])
        
        logger.info(f"ğŸ“‹ ì²˜ë¦¬ ìˆœì„œ ({len(processing_order)}ê°œ ë””ë ‰í† ë¦¬):")
        for i, dir_name in enumerate(processing_order, 1):
            logger.info(f"  {i:2d}. {dir_name}")
        
        return processing_order
    
    def get_prompt_template(self, directory_type):
        """ë””ë ‰í† ë¦¬ íƒ€ì…ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿"""
        base_prompt = """
ì´ ì´ë¯¸ì§€ë“¤ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì¡°ê±´ì— ë”°ë¼ JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

**ì°¸ì¡°: ì²« ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” ì „ì²´ ë¬¸ì„œì˜ êµ¬ì¡°ì™€ ë§¥ë½ì„ ì´í•´í•˜ê¸° ìœ„í•œ ì°¸ì¡° ì´ë¯¸ì§€ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‚˜ë¨¸ì§€ ì´ë¯¸ì§€ë“¤ì˜ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.**

**ğŸ” ë‹µì•ˆì§€ í™•ì¸ ë° í™œìš© ë°©ë²•:**
1. **ë‹µì•ˆì§€ ìš°ì„  í™•ì¸**: ì´ë¯¸ì§€ ì¤‘ì— "ì •ë‹µí‘œ", "ë‹µì•ˆì§€", "answer key", "í•´ì„¤", "ì •ë‹µê³¼ í•´ì„¤" ë“±ì´ í¬í•¨ëœ ì´ë¯¸ì§€ê°€ ìˆëŠ”ì§€ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”.
2. **ë‹µì•ˆì§€ êµ¬ì¡° íŒŒì•…**: ë‹µì•ˆì§€ì—ì„œ ë¬¸í•­ë²ˆí˜¸ì™€ ì •ë‹µë²ˆí˜¸ì˜ ë§¤ì¹­í‘œë¥¼ ì •í™•íˆ ì½ì–´ë‚´ì„¸ìš”.
3. **í•´ì„¤ ë‚´ìš© í™•ì¸**: ë‹µì•ˆì§€ì— í•´ì„¤ì´ë‚˜ í’€ì´ ê³¼ì •ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ê·¸ ë‚´ìš©ë„ í•¨ê»˜ í™•ì¸í•˜ì„¸ìš”.
4. **ë¬¸ì œ-ì •ë‹µ-í•´ì„¤ ë§¤ì¹­**: ê° ë¬¸ì œ í˜ì´ì§€ì˜ ë¬¸í•­ê³¼ ë‹µì•ˆì§€ì˜ ì •ë‹µ, í•´ì„¤ì„ ì •í™•íˆ ì—°ê²°í•˜ì„¸ìš”.
5. **ì •ë‹µ ê²€ì¦**: ë‹µì•ˆì§€ì— ëª…ì‹œëœ ì •ë‹µì´ í•´ë‹¹ ë¬¸ì œì˜ ì„ íƒì§€ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

**ì¤‘ìš” ì§€ì¹¨:**
1. í•œ í˜ì´ì§€ì— ì—¬ëŸ¬ ë¬¸ì œë‚˜ ê°œë…ì´ ìˆë‹¤ë©´ ê°ê°ì„ ë³„ë„ì˜ JSON ê°ì²´ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
2. **í‘œ, ë¶„ë¥˜í‘œ, ë„í‘œê°€ ìˆëŠ” ê²½ìš° ë°˜ë“œì‹œ ëª¨ë“  ì„¸ë¶€ ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš”.**
3. **ë¶„ë¥˜ ì½”ë“œ, ë²ˆí˜¸, ê¸°í˜¸ ë“±ë„ ì •í™•íˆ ì¶”ì¶œí•˜ì„¸ìš”.**
4. **ì˜ˆì‹œ, ì‚¬ë¡€, êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ëª¨ë‘ í¬í•¨í•˜ì„¸ìš”.**
5. **ê°œë… ì„¤ëª… ì‹œ ê´€ë ¨ëœ ëª¨ë“  í•˜ìœ„ ë¶„ë¥˜, ì„¸ë¶€ ì‚¬í•­ë„ í•¨ê»˜ ì„¤ëª…í•˜ì„¸ìš”.**

**ë¬¸ì œ ìœ í˜•ì¸ ê²½ìš° (ê°ê´€ì‹ ë¬¸ì œ):**
```json
{
  "id": "ë¬¸ì œ ê³ ìœ  ID",
  "chapter_info": {
    "chapter_number": "ê°•ì˜ ë²ˆí˜¸",
    "chapter_title": "ê°•ì˜ ì œëª©"
  },
  "problem_type": "ë¬¸ì œ ìœ í˜•",
  "context": "ë¬¸ì œì˜ ì œì‹œë¬¸ (í‘œ, ê¸€ ë“±)",
  "question": "ë¬¸ì œì˜ ë°œë¬¸",
  "stimulus_box": {
    "ã„±": "ë³´ê¸° ã„±ì˜ ë‚´ìš©",
    "ã„´": "ë³´ê¸° ã„´ì˜ ë‚´ìš©",
    "ã„·": "ë³´ê¸° ã„·ì˜ ë‚´ìš©",
    "ã„¹": "ë³´ê¸° ã„¹ì˜ ë‚´ìš©"
  },
  "options": {
    "â‘ ": "ì„ íƒì§€ 1ë²ˆ ë‚´ìš©",
    "â‘¡": "ì„ íƒì§€ 2ë²ˆ ë‚´ìš©",
    "â‘¢": "ì„ íƒì§€ 3ë²ˆ ë‚´ìš©",
    "â‘£": "ì„ íƒì§€ 4ë²ˆ ë‚´ìš©",
    "â‘¤": "ì„ íƒì§€ 5ë²ˆ ë‚´ìš©"
  },
  "answer": {
    "correct_option": "â‘¢",
    "explanation": "ë‹µì•ˆì§€ í•´ì„¤: ì œì¡°ì—…ì²´ì—ì„œ ì œí’ˆì˜ í’ˆì§ˆì„ ì¼ì •í•˜ê²Œ ìœ ì§€í•˜ê³  í˜¸í™˜ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ í‘œì¤€í™”ê°€ í•„ìš”í•˜ë‹¤. ì¶”ë¡  ê³¼ì •: ë¬¸ì œì—ì„œ ì œí’ˆ í‘œì¤€í™”ì˜ ì˜ì˜ë¥¼ ë¬»ê³  ìˆìœ¼ë©°, ì„ íƒì§€ ì¤‘ â‘¢ë²ˆì´ í‘œì¤€í™”ì˜ í•µì‹¬ ëª©ì ì¸ í’ˆì§ˆ ì¼ê´€ì„±ê³¼ í˜¸í™˜ì„±ì„ ê°€ì¥ ì •í™•íˆ ì„¤ëª…í•˜ê³  ìˆë‹¤.",
    "answer_available": true
  }
}
```

**ë‹µì•ˆì§€ê°€ ì—†ëŠ” ê²½ìš° ì˜ˆì‹œ:**
```json
{
  "id": "ë¬¸ì œ ê³ ìœ  ID",
  "chapter_info": {
    "chapter_number": "ê°•ì˜ ë²ˆí˜¸",
    "chapter_title": "ê°•ì˜ ì œëª©"
  },
  "problem_type": "ë¬¸ì œ ìœ í˜•",
  "context": "ë¬¸ì œì˜ ì œì‹œë¬¸ (í‘œ, ê¸€ ë“±)",
  "question": "ë¬¸ì œì˜ ë°œë¬¸",
  "options": {
    "â‘ ": "ì„ íƒì§€ 1ë²ˆ ë‚´ìš©",
    "â‘¡": "ì„ íƒì§€ 2ë²ˆ ë‚´ìš©",
    "â‘¢": "ì„ íƒì§€ 3ë²ˆ ë‚´ìš©",
    "â‘£": "ì„ íƒì§€ 4ë²ˆ ë‚´ìš©",
    "â‘¤": "ì„ íƒì§€ 5ë²ˆ ë‚´ìš©"
  },
  "answer": {
    "correct_option": "unknown",
    "explanation": "ì •ë‹µì´ ì œê³µë˜ì§€ ì•ŠìŒ",
    "answer_available": false
  }
}
```

**ì •ë‹µ ì²˜ë¦¬ ê°€ì´ë“œë¼ì¸:**

**ìš°ì„ ìˆœìœ„ 1: ë‹µì•ˆì§€ì—ì„œ ì •ë‹µ ë° í•´ì„¤ í™•ì¸**
1. **ë‹µì•ˆì§€ê°€ ìˆê³  í•´ì„¤ë„ í¬í•¨ëœ ê²½ìš°**: 
   - ë‹µì•ˆì§€ì—ì„œ í•´ë‹¹ ë¬¸í•­ë²ˆí˜¸ì˜ ì •ë‹µì„ ì°¾ì•„ ì •í™•íˆ ê¸°ì…
   - ë‹µì•ˆì§€ì˜ í•´ì„¤ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡  ê³¼ì •ì„ í¬í•¨í•œ ì„¤ëª… ì‘ì„±
   - `"correct_option": "â‘¢"` (ë‹µì•ˆì§€ì— í‘œì‹œëœ ì •í™•í•œ ë²ˆí˜¸)
   - `"explanation": "ë‹µì•ˆì§€ í•´ì„¤: [ë‹µì•ˆì§€ì˜ ì›ë³¸ í•´ì„¤ ë‚´ìš©]. ì¶”ë¡  ê³¼ì •: [ë¬¸ì œ ë¶„ì„ê³¼ ì •ë‹µ ë„ì¶œ ê³¼ì •]"`
   - `"answer_available": true`

2. **ë‹µì•ˆì§€ê°€ ìˆì§€ë§Œ í•´ì„¤ì´ ì—†ëŠ” ê²½ìš°**:
   - ë‹µì•ˆì§€ì—ì„œ ì •ë‹µë§Œ í™•ì¸í•˜ê³  ë¬¸ì œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê°„ë‹¨í•œ ì¶”ë¡  ì œê³µ
   - `"correct_option": "â‘¢"` (ë‹µì•ˆì§€ì— í‘œì‹œëœ ì •í™•í•œ ë²ˆí˜¸)
   - `"explanation": "ë‹µì•ˆì§€ ê¸°ì¤€ ì •ë‹µ: â‘¢. ë¬¸ì œ ë¶„ì„: [ë¬¸ì œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ê°„ë‹¨í•œ ë¶„ì„]"`
   - `"answer_available": true`

3. **ë‹µì•ˆì§€ëŠ” ìˆì§€ë§Œ í•´ë‹¹ ë¬¸í•­ì´ ì—†ëŠ” ê²½ìš°**:
   - `"correct_option": "unknown"`
   - `"explanation": "ë‹µì•ˆì§€ì— í•´ë‹¹ ë¬¸í•­ë²ˆí˜¸ê°€ ì—†ìŒ"`
   - `"answer_available": false`

**ìš°ì„ ìˆœìœ„ 2: ë¬¸ì œ í˜ì´ì§€ì—ì„œ ì •ë‹µ í™•ì¸**
4. **ë¬¸ì œ í˜ì´ì§€ì— ì •ë‹µì´ ëª…ì‹œëœ ê²½ìš°**: 
   - ë¬¸ì œ í˜ì´ì§€ì˜ ì •ë‹µì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³  ë¬¸ì œ ë¶„ì„ ì¶”ê°€
   - `"explanation": "ë¬¸ì œ ë‚´ ì •ë‹µ: [ì •ë‹µ]. ë¶„ì„: [ë¬¸ì œ í•´ê²° ê³¼ì • ì„¤ëª…]"`
   - `"answer_available": true`

**ìš°ì„ ìˆœìœ„ 3: ì •ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°**
5. **ë‹µì•ˆì§€ë„ ì—†ê³  ë¬¸ì œì—ë„ ì •ë‹µì´ ì—†ëŠ” ê²½ìš°**: 
   - `"correct_option": "unknown"`
   - `"explanation": "ì •ë‹µì´ ì œê³µë˜ì§€ ì•ŠìŒ"`
   - `"answer_available": false`

**âš ï¸ ì¤‘ìš”: í•´ì„¤ ì‘ì„± ì§€ì¹¨**
- ë‹µì•ˆì§€ì— í•´ì„¤ì´ ìˆëŠ” ê²½ìš°: í•´ì„¤ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡  ê³¼ì •ì„ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”
- ë‹µì•ˆì§€ì— ì •ë‹µë§Œ ìˆëŠ” ê²½ìš°: ë¬¸ì œ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì •ë‹µ ë„ì¶œ ê³¼ì •ì„ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”
- ì •ë‹µì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì„ì˜ ì¶”ë¡ ì„ ê¸ˆì§€í•˜ë©°, "unknown"ìœ¼ë¡œ ì²˜ë¦¬í•˜ì„¸ìš”
- ë°˜ë“œì‹œ ë‹µì•ˆì§€ë‚˜ ë¬¸ì œì˜ ì •ë‹µì„ ìš°ì„  í™•ì¸í•œ í›„ í•´ì„¤ì„ ì‘ì„±í•˜ì„¸ìš”

**ê°œë… ì„¤ëª… ìœ í˜•ì¸ ê²½ìš° (í•˜ë‚˜ì˜ ê°œë…ë‹¹ ì—¬ëŸ¬ instruction ìƒì„±):**
ì´ë¯¸ì§€ì—ì„œ í•˜ë‚˜ì˜ ê°œë…ì„ ë°œê²¬í–ˆì„ ë•Œ, í•´ë‹¹ ê°œë…ì˜ ë‚´ìš© íŠ¹ì„±ì— ë”°ë¼ ì—¬ëŸ¬ ê°œì˜ JSON ê°ì²´ë¥¼ ìƒì„±í•˜ì„¸ìš”:

```json
[
  {
    "messages": [
      {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚°ì—…ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
      {"role": "user", "content": "[ê°œë…ëª…]ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"},
      {"role": "assistant", "content": "ì •ì˜ì™€ ê¸°ë³¸ ê°œë… ì„¤ëª…"}
    ]
  },
  {
    "messages": [
      {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚°ì—…ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
      {"role": "user", "content": "[ê°œë…ëª…]ì˜ ë¶„ë¥˜ ì²´ê³„ëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?"},
      {"role": "assistant", "content": "ë¶„ë¥˜í‘œì˜ ëª¨ë“  ì„¸ë¶€ í•­ëª©ê³¼ ì½”ë“œ í¬í•¨"}
    ]
  },
  {
    "messages": [
      {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚°ì—…ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
      {"role": "user", "content": "[ê°œë…ëª…]ì˜ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì„¸ìš”."},
      {"role": "assistant", "content": "ì‹¤ì œ ì‚¬ë¡€ì™€ ì˜ˆì‹œë“¤"}
    ]
  }
]
```

**ë‚´ìš© íŠ¹ì„±ë³„ ì§ˆë¬¸ ìƒì„± ê°€ì´ë“œ:**

ğŸ“‹ **ì •ì˜/ê°œë…ì´ ìˆëŠ” ê²½ìš°:**
- "[ê°œë…ëª…]ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"
- "[ê°œë…ëª…]ì˜ ì˜ë¯¸ì™€ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."

ğŸ“Š **ë¶„ë¥˜í‘œ/ì²´ê³„ê°€ ìˆëŠ” ê²½ìš°:**
- "[ê°œë…ëª…]ì˜ ë¶„ë¥˜ ì²´ê³„ëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?"
- "[ê°œë…ëª…]ì˜ ê° ë¶„ë¥˜ë³„ íŠ¹ì§•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”."
- "KSIC ëŒ€ë¶„ë¥˜ A~UëŠ” ê°ê° ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜ìš”?"

ğŸ“ˆ **ë„í‘œ/ê·¸ë˜í”„ê°€ ìˆëŠ” ê²½ìš°:**
- "[ì£¼ì œ]ì˜ ë³€í™” ì¶”ì´ëŠ” ì–´ë–»ê²Œ ë‚˜íƒ€ë‚˜ë‚˜ìš”?"
- "ê·¸ë˜í”„ì—ì„œ ë³´ì—¬ì£¼ëŠ” [ì£¼ì œ]ì˜ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?"

ğŸ” **ì˜ˆì‹œ/ì‚¬ë¡€ê°€ ìˆëŠ” ê²½ìš°:**
- "[ê°œë…ëª…]ì˜ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì„¸ìš”."
- "[ê°œë…ëª…]ì´ ì‹¤ì œ ì‚°ì—…ì—ì„œ ì–´ë–»ê²Œ ì ìš©ë˜ë‚˜ìš”?"

âš–ï¸ **ë¹„êµí‘œ/ì¥ë‹¨ì ì´ ìˆëŠ” ê²½ìš°:**
- "Aì™€ Bì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
- "[ê°œë…ëª…]ì˜ ì¥ì ê³¼ ë‹¨ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"

ğŸ”„ **ê³¼ì •/ë‹¨ê³„ê°€ ìˆëŠ” ê²½ìš°:**
- "[ê³¼ì •ëª…]ì˜ ë‹¨ê³„ë³„ ì ˆì°¨ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”."
- "[ê°œë…ëª…]ì€ ì–´ë–¤ ê³¼ì •ì„ ê±°ì³ ë°œì „í–ˆë‚˜ìš”?"

ğŸ¯ **í™œìš©/ëª©ì ì´ ìˆëŠ” ê²½ìš°:**
- "[ê°œë…ëª…]ì˜ í™œìš© ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
- "[ê°œë…ëª…]ì´ ì™œ ì¤‘ìš”í•œê°€ìš”?"

**ì¢‹ì€ ê°œë… ì„¤ëª… ì˜ˆì‹œ (KSICì—ì„œ ì—¬ëŸ¬ instruction ìƒì„±):**
```json
[
  {
    "messages": [
      {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚°ì—…ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
      {"role": "user", "content": "í•œêµ­í‘œì¤€ì‚°ì—…ë¶„ë¥˜(KSIC)ë€ ë¬´ì—‡ì¸ê°€ìš”?"},
      {"role": "assistant", "content": "í•œêµ­í‘œì¤€ì‚°ì—…ë¶„ë¥˜(KSIC)ëŠ” êµ­ë‚´ ëª¨ë“  ì‚°ì—… í™œë™ì„ ìƒì‚° ë‹¨ìœ„ì˜ ìœ ì‚¬ì„±ì— ë”°ë¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ë¥˜í•œ êµ­ê°€ í‘œì¤€ì…ë‹ˆë‹¤. í†µê³„ì²­ì—ì„œ ê´€ë¦¬í•˜ë©°, ê³µê³µ í–‰ì •, í†µê³„ ì‘ì„±, ì‚°ì—… ì •ì±… ìˆ˜ë¦½ ë“±ì— í™œìš©ë©ë‹ˆë‹¤."}
    ]
  },
  {
    "messages": [
      {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚°ì—…ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
      {"role": "user", "content": "KSICì˜ ë¶„ë¥˜ ì²´ê³„ëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?"},
      {"role": "assistant", "content": "KSICëŠ” 5ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:\n1. ëŒ€ë¶„ë¥˜: A~U (21ê°œ ë¶„ë¥˜)\n2. ì¤‘ë¶„ë¥˜: 2ìë¦¬ ìˆ«ì (77ê°œ ë¶„ë¥˜)\n3. ì†Œë¶„ë¥˜: 3ìë¦¬ ìˆ«ì (232ê°œ ë¶„ë¥˜)\n4. ì„¸ë¶„ë¥˜: 4ìë¦¬ ìˆ«ì (495ê°œ ë¶„ë¥˜)\n5. ì„¸ì„¸ë¶„ë¥˜: 5ìë¦¬ ìˆ«ì (1,196ê°œ ë¶„ë¥˜)"}
    ]
  },
  {
    "messages": [
      {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚°ì—…ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
      {"role": "user", "content": "KSIC ëŒ€ë¶„ë¥˜ A~UëŠ” ê°ê° ë¬´ì—‡ì„ ì˜ë¯¸í•˜ë‚˜ìš”?"},
      {"role": "assistant", "content": "KSIC ëŒ€ë¶„ë¥˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n- A: ë†ì—…, ì„ì—… ë° ì–´ì—…\n- B: ê´‘ì—…\n- C: ì œì¡°ì—…\n- D: ì „ê¸°, ê°€ìŠ¤, ì¦ê¸° ë° ê³µê¸°ì¡°ì ˆ ê³µê¸‰ì—…\n- E: ìˆ˜ë„, í•˜ìˆ˜ ë° íê¸°ë¬¼ ì²˜ë¦¬, ì›ë£Œì¬ìƒì—…\n- F: ê±´ì„¤ì—…\n- G: ë„ë§¤ ë° ì†Œë§¤ì—…\n- H: ìš´ìˆ˜ ë° ì°½ê³ ì—…\n- I: ìˆ™ë°• ë° ìŒì‹ì ì—…\n- J: ì •ë³´í†µì‹ ì—…\n- K: ê¸ˆìœµ ë° ë³´í—˜ì—…\n- L: ë¶€ë™ì‚°ì—…\n- M: ì „ë¬¸, ê³¼í•™ ë° ê¸°ìˆ  ì„œë¹„ìŠ¤ì—…\n- N: ì‚¬ì—…ì‹œì„¤ ê´€ë¦¬, ì‚¬ì—… ì§€ì› ë° ì„ëŒ€ ì„œë¹„ìŠ¤ì—…\n- O: ê³µê³µ í–‰ì •, êµ­ë°© ë° ì‚¬íšŒë³´ì¥ í–‰ì •\n- P: êµìœ¡ ì„œë¹„ìŠ¤ì—…\n- Q: ë³´ê±´ì—… ë° ì‚¬íšŒë³µì§€ ì„œë¹„ìŠ¤ì—…\n- R: ì˜ˆìˆ , ìŠ¤í¬ì¸  ë° ì—¬ê°€ê´€ë ¨ ì„œë¹„ìŠ¤ì—…\n- S: í˜‘íšŒ ë° ë‹¨ì²´, ìˆ˜ë¦¬ ë° ê¸°íƒ€ ê°œì¸ ì„œë¹„ìŠ¤ì—…\n- T: ê°€êµ¬ ë‚´ ê³ ìš©í™œë™ ë° ë‹¬ë¦¬ ë¶„ë¥˜ë˜ì§€ ì•Šì€ ìê°€ì†Œë¹„ ìƒì‚°í™œë™\n- U: êµ­ì œ ë° ì™¸êµ­ê¸°ê´€"}
    ]
  },
  {
    "messages": [
      {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚°ì—…ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
      {"role": "user", "content": "KSICì˜ í™œìš© ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"},
      {"role": "assistant", "content": "KSICëŠ” ë‹¤ìŒê³¼ ê°™ì€ ëª©ì ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤:\n1. êµ­ë¯¼ê³„ì • ì‘ì„± ë° ê²½ì œë¶„ì„\n2. ì‚°ì—…êµ¬ì¡° ë¶„ì„ ë° ì •ì±… ìˆ˜ë¦½\n3. í†µê³„ ì¡°ì‚¬ì˜ í‘œì¤€í™”\n4. êµ­ì œ ë¹„êµ í†µê³„ ì‘ì„±\n5. í–‰ì •ì—…ë¬´ì˜ íš¨ìœ¨ì„± ì œê³ \n6. ë¯¼ê°„ ê¸°ì—…ì˜ ì‹œì¥ ë¶„ì„ ë° ì „ëµ ìˆ˜ë¦½ ì§€ì›"}
    ]
  }
]
```

**ì„¸ë¶€ ì¶”ì¶œ ì§€ì¹¨:**
1. ê° ë¬¸ì œ/ê°œë…ì€ ë³„ë„ì˜ JSON ê°ì²´ë¡œ ë¶„ë¦¬
2. **í•˜ë‚˜ì˜ ê°œë…ì—ì„œ ì—¬ëŸ¬ ì¸¡ë©´ì˜ ì§ˆë¬¸ì„ ìƒì„±** (ì •ì˜â†’ë¶„ë¥˜â†’ì˜ˆì‹œâ†’í™œìš© ë“±)
3. ì—¬ëŸ¬ ê°œì˜ JSON ê°ì²´ê°€ ìˆë‹¤ë©´ JSON ë°°ì—´ë¡œ ë°˜í™˜
4. ì´ë¯¸ì§€ì—ì„œ ì‹ë³„ë˜ëŠ” ê°•ì˜ ë²ˆí˜¸ì™€ ì œëª©ì„ ì •í™•íˆ ì¶”ì¶œ
5. ë‹µì•ˆê³¼ í•´ì„¤ì„ ì •í™•íˆ ë§¤ì¹­
6. ê°œë… ì„¤ëª…ì˜ ê²½ìš° ë‚´ìš© íŠ¹ì„±ì„ íŒŒì•…í•˜ì—¬ ì ì ˆí•œ ì§ˆë¬¸ë“¤ì„ ìƒì„±

**ê°œë…ë³„ ì¶”ì¶œ ì „ëµ:**
- í•˜ë‚˜ì˜ ê°œë… ë°œê²¬ ì‹œ â†’ í•´ë‹¹ ê°œë…ì˜ ëª¨ë“  ì¸¡ë©´ì„ ë‹¤ê°ë„ë¡œ ì§ˆë¬¸
- ì •ì˜ë§Œ ìˆì–´ë„ â†’ ìµœì†Œ 2-3ê°œì˜ ì§ˆë¬¸ (ì •ì˜, íŠ¹ì§•, ì¤‘ìš”ì„±)
- ë¶„ë¥˜í‘œê°€ ìˆìœ¼ë©´ â†’ ì¶”ê°€ë¡œ ë¶„ë¥˜ ì²´ê³„ ê´€ë ¨ ì§ˆë¬¸
- ì˜ˆì‹œê°€ ìˆìœ¼ë©´ â†’ ì¶”ê°€ë¡œ ì‹¤ì œ ì ìš© ì‚¬ë¡€ ì§ˆë¬¸

**íŠ¹ë³„íˆ ë†“ì¹˜ì§€ ë§ì•„ì•¼ í•  ì •ë³´:**
- ë¶„ë¥˜í‘œì˜ ëª¨ë“  í•­ëª© (ì˜ˆ: KSIC A~U ëŒ€ë¶„ë¥˜, ì¤‘ë¶„ë¥˜ ë²ˆí˜¸ ë“±)
- ë„í‘œ, ê·¸ë˜í”„ì˜ ìˆ˜ì¹˜ì™€ ë¼ë²¨ (ì¶• ì œëª©, ë²”ë¡€, êµ¬ì²´ì  ê°’)
- ë‹¨ê³„ë³„ í”„ë¡œì„¸ìŠ¤ë‚˜ ì ˆì°¨ (í™”ì‚´í‘œë¡œ ì—°ê²°ëœ ê³¼ì •ë“¤)
- ê³µì‹, ê³„ì‚°ë²•, ë¹„ìœ¨
- êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ì‚¬ë¡€ (íšŒì‚¬ëª…, ì œí’ˆëª… ë“±)
- ì—°ë„, ì‹œëŒ€ êµ¬ë¶„, ì‹œê¸°ë³„ íŠ¹ì§•
- ìš©ì–´ì˜ ì •ì˜ì™€ íŠ¹ì§•, êµ¬ì„± ìš”ì†Œ
- ì¥ë‹¨ì , ë¬¸ì œì , í•œê³„
- ê´€ë ¨ ë²•ê·œë‚˜ ê¸°ì¤€, ì •ì±…
- ë¹„êµí‘œì˜ ëª¨ë“  í•­ëª©ê³¼ ì°¨ì´ì 
- ë°œì „ ë‹¨ê³„ë‚˜ ë³€í™” ê³¼ì •

**ì‹¤ì œ ì§ˆë¬¸ ìƒì„± ì˜ˆì‹œ:**
"ì½œë¦° í´ë¼í¬ì˜ ì‚°ì—… ë¶„ë¥˜" ê°œë…ì´ ìˆë‹¤ë©´:
- "ì½œë¦° í´ë¼í¬ì˜ ì‚°ì—… ë¶„ë¥˜ë€ ë¬´ì—‡ì¸ê°€ìš”?"
- "í´ë¼í¬ëŠ” ì‚°ì—…ì„ ì–´ë–»ê²Œ 1ì°¨, 2ì°¨, 3ì°¨ë¡œ êµ¬ë¶„í–ˆë‚˜ìš”?"
- "í´ë¼í¬ ë¶„ë¥˜ë²•ì˜ ê° ì‚°ì—…ë³„ íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?"
- "í´ë¼í¬ ë¶„ë¥˜ë²•ì´ ê²½ì œ ë¶„ì„ì—ì„œ ì¤‘ìš”í•œ ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?"

í˜„ì¬ ë¶„ì„í•  ì´ë¯¸ì§€ë“¤ì˜ ë‚´ìš©ì„ ìœ„ ì§€ì¹¨ì— ë”°ë¼ JSONìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
"""
        return base_prompt
    
    def load_images_from_directory(self, directory_path):
        """ë””ë ‰í† ë¦¬ì—ì„œ ëª¨ë“  PNG ì´ë¯¸ì§€ ë¡œë“œ"""
        png_files = sorted(list(directory_path.glob("*.png")))
        images = []
        
        for png_file in png_files:
            try:
                image = Image.open(png_file)
                images.append((png_file.name, image))
            except Exception as e:
                logger.error(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ {png_file}: {str(e)}")
        
        logger.info(f"  ğŸ“¸ ë¡œë“œëœ ì´ë¯¸ì§€: {len(images)}ê°œ")
        return images
    
    def process_directory(self, directory_name, images):
        """ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬"""
        directory_type = "chapter" if "Chapter" in directory_name else "exam"
        
        # EXAM ì´ë¯¸ì§€ë“¤ì˜ ê²½ìš° ì°¸ì¡° ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        use_reference = self.reference_image and directory_type != "exam"
        reference_info = " + ì°¸ì¡°ì´ë¯¸ì§€" if use_reference else ""
        logger.info(f"    ğŸ”„ ì²˜ë¦¬ ì¤‘ ({len(images)}ê°œ ì´ë¯¸ì§€{reference_info})")
        
        try:
            # í”„ë¡¬í”„íŠ¸ì™€ ì´ë¯¸ì§€ë“¤ ì¤€ë¹„
            prompt = self.get_prompt_template(directory_type)
            content = [prompt]
            
            # ì°¸ì¡° ì´ë¯¸ì§€ ë¨¼ì € ì¶”ê°€ (Chapter íƒ€ì…ì¸ ê²½ìš°ì—ë§Œ)
            if use_reference:
                content.append(self.reference_image)
            
            # ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  ì´ë¯¸ì§€ë“¤ ì¶”ê°€
            for img_name, img in images:
                content.append(img)
            
            # Gemini API í˜¸ì¶œ
            response = self.model.generate_content(content)
            response_text = response.text.strip()
            
            # ë””ë²„ê¹…ìš© ì‘ë‹µ ì¶œë ¥
            logger.info(f"[DEBUG]: Gemini ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì)")
            logger.info(f"[DEBUG]: {response_text[:500]}...")
            if len(response_text) > 500:
                logger.info(f"[DEBUG]: ì „ì²´ ê¸¸ì´: {len(response_text)} ë¬¸ì")
            
            # ê²°ê³¼ ì €ì¥
            result = {
                "directory": directory_name,
                "reference_image": "page_001.png" if use_reference else None,
                "image_files": [img_name for img_name, _ in images],
                "response": response_text,
                "processed_at": datetime.now().isoformat()
            }
            
            logger.info(f"    âœ… ì²˜ë¦¬ ì™„ë£Œ")
            
            # API í˜¸ì¶œ ì œí•œ ê³ ë ¤
            time.sleep(3)
            
            return result
            
        except Exception as e:
            logger.error(f"    âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return None
    
    def process_all_directories(self):
        """ëª¨ë“  ë””ë ‰í† ë¦¬ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬"""
        processing_order = self.get_processing_order()
        all_results = []
        
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸš€ ë°ì´í„°ì…‹ ìƒì„± ì‘ì—… ì‹œì‘")
        logger.info(f"{'='*70}")
        
        total_dirs = len(processing_order)
        
        for i, directory_name in enumerate(processing_order, 1):
            directory_path = self.images_dir / directory_name
            
            logger.info(f"\nğŸ“‚ [{i:2d}/{total_dirs}] {directory_name} ì²˜ë¦¬ ì¤‘...")
            logger.info(f"{'â”€'*50}")
            
            if not directory_path.exists():
                logger.warning(f"âš ï¸  ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {directory_name}")
                continue
            
            # ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ë“¤ ë¡œë“œ
            images = self.load_images_from_directory(directory_path)
            
            if not images:
                logger.warning(f"âš ï¸  ì´ë¯¸ì§€ê°€ ì—†ìŒ: {directory_name}")
                continue
            
            # ë””ë ‰í† ë¦¬ ì²˜ë¦¬ (ëª¨ë“  ì´ë¯¸ì§€ í•œ ë²ˆì—)
            directory_result = self.process_directory(directory_name, images)
            
            if directory_result:
                all_results.append(directory_result)
                
                # ë””ë ‰í† ë¦¬ë³„ ì¤‘ê°„ ì €ì¥
                self.save_directory_results(directory_name, [directory_result])
                
                logger.info(f"âœ… {directory_name} ì™„ë£Œ")
            else:
                logger.error(f"âŒ {directory_name} ì²˜ë¦¬ ì‹¤íŒ¨")
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        self.save_final_results(all_results)
        
        return all_results
    
    def clean_json_text(self, text):
        """JSON í…ìŠ¤íŠ¸ ì •ë¦¬ (ê°„ë‹¨í•˜ê³  ì§ì ‘ì ì¸ ë°©ë²•)"""
        import re
        
        logger.info(f"[DEBUG]: JSON í…ìŠ¤íŠ¸ ì •ë¦¬ ì‹œì‘ (ì›ë³¸ ê¸¸ì´: {len(text)})")
        
        # 1. ì œì–´ ë¬¸ì ì œê±° (íƒ­, ê°œí–‰ ë“±ì€ ìœ ì§€)
        text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', text)
        logger.info(f"[DEBUG]: ì œì–´ ë¬¸ì ì œê±° ì™„ë£Œ")
        
        # 2. ì˜ëª»ëœ ë”°ì˜´í‘œ ìˆ˜ì •
        text = text.replace('"', '"').replace('"', '"')
        text = text.replace("'", "'").replace("'", "'")
        logger.info(f"[DEBUG]: ë”°ì˜´í‘œ ì •ê·œí™” ì™„ë£Œ")
        
        # 3. JSON êµ¬ë¬¸ ì˜¤ë¥˜ ìˆ˜ì • (ìˆœì°¨ì ì´ê³  ì•ˆì „í•œ ë°©ë²•)
        logger.info(f"[DEBUG]: ìˆœì°¨ì  JSON êµ¬ë¬¸ ì˜¤ë¥˜ ìˆ˜ì • ì‹œì‘")
        
        original_text = text
        fixed_count = 0
        
        # ë‹¨ê³„ 1: ê°€ì¥ ê¸°ë³¸ì ì¸ íŒ¨í„´ ìˆ˜ì • (í•œ ë²ˆì— í•˜ë‚˜ì”©)
        basic_fixes = [
            ('      "assistant",\n        "content":', '      "role": "assistant",\n        "content":'),
            ('      "user",\n        "content":', '      "role": "user",\n        "content":'),
            ('      "system",\n        "content":', '      "role": "system",\n        "content":'),
            ('    "assistant",\n    "content":', '    "role": "assistant",\n    "content":'),
            ('    "user",\n    "content":', '    "role": "user",\n    "content":'),
            ('    "system",\n    "content":', '    "role": "system",\n    "content":'),
        ]
        
        for old_pattern, new_pattern in basic_fixes:
            if old_pattern in text:
                text = text.replace(old_pattern, new_pattern)
                fixed_count += 1
                logger.info(f"[DEBUG]: ê¸°ë³¸ ìˆ˜ì • ({fixed_count}): {old_pattern[:20]}... â†’ {new_pattern[:20]}...")
        
        # ë‹¨ê³„ 2: ì¤‘ê´„í˜¸ ì§í›„ íŒ¨í„´ ìˆ˜ì •
        brace_fixes = [
            ('{\n        "assistant",', '{\n        "role": "assistant",'),
            ('{\n        "user",', '{\n        "role": "user",'),
            ('{\n        "system",', '{\n        "role": "system",'),
            ('{\n      "assistant",', '{\n      "role": "assistant",'),
            ('{\n      "user",', '{\n      "role": "user",'),
            ('{\n      "system",', '{\n      "role": "system",'),
        ]
        
        for old_pattern, new_pattern in brace_fixes:
            if old_pattern in text:
                text = text.replace(old_pattern, new_pattern)
                fixed_count += 1
                logger.info(f"[DEBUG]: ì¤‘ê´„í˜¸ ìˆ˜ì • ({fixed_count}): {old_pattern[:15]}... â†’ {new_pattern[:15]}...")
        
        # ë‹¨ê³„ 3: ë‚¨ì€ ê°„ë‹¨í•œ íŒ¨í„´ë“¤
        remaining_fixes = [
            ('"assistant",\n        "content":', '"role": "assistant",\n        "content":'),
            ('"user",\n        "content":', '"role": "user",\n        "content":'),
            ('"system",\n        "content":', '"role": "system",\n        "content":'),
        ]
        
        for old_pattern, new_pattern in remaining_fixes:
            if old_pattern in text and '"role":' not in text[max(0, text.find(old_pattern)-20):text.find(old_pattern)]:
                text = text.replace(old_pattern, new_pattern)
                fixed_count += 1
                logger.info(f"[DEBUG]: ë‚¨ì€ íŒ¨í„´ ìˆ˜ì • ({fixed_count}): {old_pattern[:20]}...")
        
        # ë‹¨ê³„ 4: í˜¹ì‹œ ì¤‘ë³µëœ role í‚¤ê°€ ìƒê²¼ë‹¤ë©´ ì •ë¦¬
        if '"role": "role":' in text:
            text = text.replace('"role": "role":', '"role":')
            logger.info(f"[DEBUG]: ì¤‘ë³µ role í‚¤ ì •ë¦¬ ì™„ë£Œ")
            fixed_count += 1
        
        if '"role": "role": "role":' in text:
            text = text.replace('"role": "role": "role":', '"role":')
            logger.info(f"[DEBUG]: 3ì¤‘ ì¤‘ë³µ role í‚¤ ì •ë¦¬ ì™„ë£Œ")
            fixed_count += 1
        
        if text != original_text:
            logger.info(f"[DEBUG]: JSON êµ¬ë¬¸ ì˜¤ë¥˜ ìˆ˜ì • ì™„ë£Œ ({fixed_count}ê°œ ìˆ˜ì •, ê¸¸ì´ {len(original_text)} â†’ {len(text)})")
        else:
            logger.info(f"[DEBUG]: JSON êµ¬ë¬¸ ì˜¤ë¥˜ ìˆ˜ì • ë¶ˆí•„ìš” (ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•ì‹)")
        
        # 4. ì¤„ë°”ê¿ˆ ë¬¸ì ì •ê·œí™”
        text = text.replace('\r\n', '\n').replace('\r', '\n')
        
        # 5. ì—°ì†ëœ ê³µë°± ì •ë¦¬
        text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
        
        logger.info(f"[DEBUG]: JSON í…ìŠ¤íŠ¸ ì •ë¦¬ ì™„ë£Œ (ìµœì¢… ê¸¸ì´: {len(text)})")
        return text
    
    def validate_and_fix_answer_fields(self, parsed_data):
        """ë‹µì•ˆ í•„ë“œ ê²€ì¦ ë° ë³´ì™„ (ë‹µì•ˆì§€ ì²˜ë¦¬ í¬í•¨)"""
        fixed_count = 0
        logger.info(f"[DEBUG]: ë‹µì•ˆ í•„ë“œ ê²€ì¦ ì‹œì‘ - {len(parsed_data)}ê°œ í•­ëª©")
        
        for i, item in enumerate(parsed_data):
            # ê°ê´€ì‹ ë¬¸ì œì¸ ê²½ìš° ë‹µì•ˆ í•„ë“œ ê²€ì¦
            if isinstance(item, dict) and item.get("problem_type") and "ê°ê´€ì‹" in str(item.get("problem_type", "")):
                logger.info(f"[DEBUG]: í•­ëª© {i+1} - ê°ê´€ì‹ ë¬¸ì œ ê²€ì¦ ì¤‘")
                answer = item.get("answer", {})
                
                # answer í•„ë“œê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°
                if not answer or answer is None:
                    logger.info(f"[DEBUG]: í•­ëª© {i+1} - answer í•„ë“œ ëˆ„ë½, ê¸°ë³¸ê°’ ì„¤ì •")
                    item["answer"] = {
                        "correct_option": "unknown",
                        "explanation": "ì •ë‹µì´ ì œê³µë˜ì§€ ì•ŠìŒ (ë‹µì•ˆì§€ ë˜ëŠ” ë¬¸ì œì—ì„œ í™•ì¸ í•„ìš”)",
                        "answer_available": False
                    }
                    fixed_count += 1
                else:
                    # correct_optionì´ Noneì´ê±°ë‚˜ ë¹ˆ ê°’ì¸ ê²½ìš°
                    if not answer.get("correct_option") or answer.get("correct_option") in [None, "", "null", "NULL"]:
                        logger.info(f"[DEBUG]: í•­ëª© {i+1} - correct_option ìˆ˜ì •: '{answer.get('correct_option')}' â†’ 'unknown'")
                        answer["correct_option"] = "unknown"
                        if not answer.get("explanation"):
                            answer["explanation"] = "ì •ë‹µì´ ì œê³µë˜ì§€ ì•ŠìŒ"
                        fixed_count += 1
                    
                    # explanationì´ Noneì´ê±°ë‚˜ ë¹ˆ ê°’ì¸ ê²½ìš°
                    if not answer.get("explanation") or answer.get("explanation") in [None, "", "null", "NULL"]:
                        # correct_optionì´ ìˆëŠ” ê²½ìš° ë‹µì•ˆì§€ì—ì„œ ê°€ì ¸ì˜¨ ê²ƒìœ¼ë¡œ ê°„ì£¼
                        if answer.get("correct_option") and answer.get("correct_option") != "unknown":
                            answer["explanation"] = f"ë‹µì•ˆì§€ ê¸°ì¤€ ì •ë‹µ: {answer.get('correct_option')}. ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•¨"
                        else:
                            answer["explanation"] = "ì •ë‹µì´ ì œê³µë˜ì§€ ì•ŠìŒ"
                        fixed_count += 1
                    
                    # answer_available í•„ë“œ ì¶”ê°€/ìˆ˜ì •
                    if "answer_available" not in answer:
                        answer["answer_available"] = (
                            answer.get("correct_option") not in [None, "", "unknown", "null", "NULL"] and
                            answer.get("correct_option") is not None
                        )
                    
                    # ë‹µì•ˆì§€ ê¸°ë°˜ ì •ë‹µì¸ì§€ í™•ì¸í•˜ì—¬ explanation ê°œì„ 
                    if (answer.get("correct_option") not in ["unknown", None, "", "null", "NULL"] and
                        len(str(answer.get("explanation", "")).strip()) < 20):  # ë§¤ìš° ì§§ì€ ì„¤ëª…ì¸ ê²½ìš°
                        # ì„¤ëª…ì´ ë¶€ì¡±í•œ ê²½ìš° ë‹µì•ˆì§€ í•´ì„¤ ì°¸ì¡° ìš”ì²­ ë©”ì‹œì§€ ì¶”ê°€
                        old_explanation = answer.get("explanation", "")
                        answer["explanation"] = f"ë‹µì•ˆì§€ ê¸°ì¤€ ì •ë‹µ: {answer.get('correct_option')}. {old_explanation} (ë‹µì•ˆì§€ í•´ì„¤ ì°¸ì¡° í•„ìš”)".strip()
        
        if fixed_count > 0:
            logger.info(f"[DEBUG]: ğŸ”§ ë‹µì•ˆ í•„ë“œ ë³´ì™„ ì™„ë£Œ: {fixed_count}ê°œ í•­ëª© ìˆ˜ì •ë¨")
        else:
            logger.info(f"[DEBUG]: âœ… ëª¨ë“  ë‹µì•ˆ í•„ë“œê°€ ì •ìƒ ìƒíƒœ")
        
        return parsed_data
    
    def parse_gemini_response(self, response_text):
        """Gemini ì‘ë‹µì—ì„œ JSON ë°ì´í„° ì¶”ì¶œ ë° íŒŒì‹± (ê°œì„ ëœ ë²„ì „)"""
        original_text = response_text
        
        try:
            logger.info(f"[DEBUG]: JSON íŒŒì‹± ì‹œì‘")
            
            # 1ë‹¨ê³„: ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
                logger.info(f"[DEBUG]: ```json ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ")
            elif "```" in response_text:
                # ì²« ë²ˆì§¸ ``` ì´í›„, ë§ˆì§€ë§‰ ``` ì´ì „ ë‚´ìš© ì¶”ì¶œ
                parts = response_text.split("```")
                if len(parts) >= 3:
                    response_text = parts[1].strip()
                    logger.info(f"[DEBUG]: ``` ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ ({len(parts)}ê°œ ë¶€ë¶„)")
                else:
                    response_text = response_text.replace("```", "").strip()
                    logger.info(f"[DEBUG]: ``` ê¸°í˜¸ ì œê±°")
            else:
                logger.info(f"[DEBUG]: ì½”ë“œ ë¸”ë¡ ì—†ìŒ, ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
            
            # 2ë‹¨ê³„: JSON í…ìŠ¤íŠ¸ ì •ë¦¬
            cleaned_response = self.clean_json_text(response_text)
            logger.info(f"[DEBUG]: í…ìŠ¤íŠ¸ ì •ë¦¬ ì™„ë£Œ (ê¸¸ì´: {len(cleaned_response)})")
            
            # 3ë‹¨ê³„: JSON íŒŒì‹± ì‹œë„
            logger.info(f"[DEBUG]: JSON íŒŒì‹± ì‹œë„ ì¤‘...")
            parsed_data = json.loads(cleaned_response)
            
            # 4ë‹¨ê³„: ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if not isinstance(parsed_data, list):
                parsed_data = [parsed_data]
                
            # 5ë‹¨ê³„: ë‹µì•ˆ í•„ë“œ ê²€ì¦ ë° ë³´ì™„
            parsed_data = self.validate_and_fix_answer_fields(parsed_data)
            
            logger.info(f"[DEBUG]: âœ… JSON íŒŒì‹± ì„±ê³µ: {len(parsed_data)}ê°œ í•­ëª©")
            return parsed_data
            
        except json.JSONDecodeError as e:
            logger.error(f"[DEBUG]: âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            logger.error(f"[DEBUG]: ì‹¤íŒ¨ ìœ„ì¹˜: line {e.lineno}, column {e.colno}")
            logger.error(f"[DEBUG]: ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ì¼ë¶€: {cleaned_response[:300]}...")
            
            # ì‹¤íŒ¨í•œ ë¶€ë¶„ ì£¼ë³€ í…ìŠ¤íŠ¸ ì¶œë ¥
            try:
                lines = cleaned_response.split('\n')
                if e.lineno <= len(lines):
                    logger.error(f"[DEBUG]: ë¬¸ì œ ë¼ì¸ {e.lineno}: {lines[e.lineno-1] if e.lineno > 0 else 'N/A'}")
            except:
                pass
            
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œì—ë„ ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜ (íŒŒì‹± ì‹œë„ë¥¼ ìœ„í•´)
            logger.info(f"[DEBUG]: ë¶€ë¶„ íŒŒì‹± ì‹œë„ ì¤‘...")
            partial_data = self.try_partial_json_parsing(cleaned_response, original_text)
            if partial_data:
                return self.validate_and_fix_answer_fields(partial_data)
            return partial_data
            
        except Exception as e:
            logger.error(f"[DEBUG]: âŒ ì˜ˆìƒì¹˜ ëª»í•œ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            logger.error(f"[DEBUG]: ì›ë³¸ ì‘ë‹µ ì¼ë¶€: {original_text[:300]}...")
            return []
    
    def try_partial_json_parsing(self, cleaned_text, original_text):
        """ë¶€ë¶„ì  JSON íŒŒì‹± ì‹œë„ (ê°•í™”ëœ ë²„ì „)"""
        try:
            logger.info(f"[DEBUG]: ë¶€ë¶„ íŒŒì‹± ì „ëµ 1 - ë°°ì—´ ë˜í•‘ ì‹œë„")
            # 1. ë°°ì—´ë¡œ ê°ì‹¸ì„œ ì‹œë„
            if not cleaned_text.strip().startswith('['):
                wrapped_text = f"[{cleaned_text}]"
                try:
                    parsed_data = json.loads(wrapped_text)
                    logger.warning(f"[DEBUG]: âœ… ë°°ì—´ ë˜í•‘ìœ¼ë¡œ íŒŒì‹± ì„±ê³µ: {len(parsed_data)}ê°œ í•­ëª©")
                    return parsed_data
                except Exception as wrap_error:
                    logger.info(f"[DEBUG]: ë°°ì—´ ë˜í•‘ ì‹¤íŒ¨: {str(wrap_error)}")
                    pass
            
            # 2. ì—¬ëŸ¬ ê°œì˜ ì™„ì „í•œ JSON ê°ì²´ ì¶”ì¶œ ì‹œë„ (ëª¨ë“  ê°ì²´ ì¶”ì¶œ)
            logger.info(f"[DEBUG]: ë¶€ë¶„ íŒŒì‹± ì „ëµ 2 - ëª¨ë“  ì™„ì „í•œ ê°ì²´ ì¶”ì¶œ ì‹œë„")
            objects = []
            brace_count = 0
            start_pos = None
            i = 0
            
            while i < len(cleaned_text):
                char = cleaned_text[i]
                if char == '{':
                    if brace_count == 0:  # ìƒˆë¡œìš´ ê°ì²´ ì‹œì‘
                        start_pos = i
                    brace_count += 1
                elif char == '}':
                    brace_count -= 1
                    if brace_count == 0 and start_pos is not None:
                        # ì™„ì „í•œ ê°ì²´ ë°œê²¬
                        single_object = cleaned_text[start_pos:i+1]
                        logger.info(f"[DEBUG]: ê°ì²´ ë°œê²¬ (ìœ„ì¹˜: {start_pos}-{i}, ê¸¸ì´: {len(single_object)})")
                        try:
                            parsed_obj = json.loads(single_object)
                            objects.append(parsed_obj)
                            logger.info(f"[DEBUG]: âœ… ê°ì²´ íŒŒì‹± ì„±ê³µ ({len(objects)}ë²ˆì§¸)")
                        except Exception as obj_error:
                            logger.error(f"[DEBUG]: ê°ì²´ íŒŒì‹± ì‹¤íŒ¨ ({len(objects)+1}ë²ˆì§¸): {str(obj_error)}")
                        start_pos = None
                i += 1
            
            if objects:
                logger.warning(f"[DEBUG]: âœ… ë¶€ë¶„ íŒŒì‹± ì„±ê³µ: {len(objects)}ê°œ í•­ëª© ì¶”ì¶œ")
                return objects
            
            # 3. ì²« ë²ˆì§¸ ì™„ì „í•œ JSON ê°ì²´ë§Œ ì¶”ì¶œ (ê¸°ì¡´ ë°©ì‹)
            logger.info(f"[DEBUG]: ë¶€ë¶„ íŒŒì‹± ì „ëµ 3 - ì²« ë²ˆì§¸ ì™„ì „í•œ ê°ì²´ë§Œ ì¶”ì¶œ ì‹œë„")
            brace_count = 0
            start_pos = cleaned_text.find('{')
            if start_pos != -1:
                logger.info(f"[DEBUG]: ì²« ë²ˆì§¸ '{{' ìœ„ì¹˜: {start_pos}")
                for i, char in enumerate(cleaned_text[start_pos:], start_pos):
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            # ì™„ì „í•œ ê°ì²´ ë°œê²¬
                            single_object = cleaned_text[start_pos:i+1]
                            logger.info(f"[DEBUG]: ì™„ì „í•œ ê°ì²´ ë°œê²¬ (ê¸¸ì´: {len(single_object)})")
                            try:
                                parsed_data = json.loads(single_object)
                                logger.warning(f"[DEBUG]: âœ… ë¶€ë¶„ íŒŒì‹± ì„±ê³µ: 1ê°œ í•­ëª© ì¶”ì¶œ")
                                return [parsed_data]
                            except Exception as obj_error:
                                logger.error(f"[DEBUG]: ê°ì²´ íŒŒì‹± ì‹¤íŒ¨: {str(obj_error)}")
                                break
            else:
                logger.info(f"[DEBUG]: '{{' ê¸°í˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            
            # 4. ë¼ì¸ë³„ ê°ì²´ ì¶”ì¶œ ì‹œë„
            logger.info(f"[DEBUG]: ë¶€ë¶„ íŒŒì‹± ì „ëµ 4 - ë¼ì¸ë³„ ê°ì²´ ì¶”ì¶œ ì‹œë„")
            lines = cleaned_text.split('\n')
            objects = []
            current_object = ""
            brace_count = 0
            
            for line_num, line in enumerate(lines):
                current_object += line + '\n'
                for char in line:
                    if char == '{':
                        brace_count += 1
                    elif char == '}':
                        brace_count -= 1
                
                if brace_count == 0 and current_object.strip():
                    # ì™„ì „í•œ ê°ì²´ê°€ ë  ìˆ˜ ìˆìŒ
                    obj_text = current_object.strip()
                    if obj_text.startswith('{') and obj_text.endswith('}'):
                        try:
                            parsed_obj = json.loads(obj_text)
                            objects.append(parsed_obj)
                            logger.info(f"[DEBUG]: âœ… ë¼ì¸ë³„ ê°ì²´ íŒŒì‹± ì„±ê³µ ({len(objects)}ë²ˆì§¸, ë¼ì¸ {line_num})")
                        except:
                            pass
                    current_object = ""
            
            if objects:
                logger.warning(f"[DEBUG]: âœ… ë¼ì¸ë³„ íŒŒì‹± ì„±ê³µ: {len(objects)}ê°œ í•­ëª© ì¶”ì¶œ")
                return objects
            
            logger.error(f"[DEBUG]: âŒ ëª¨ë“  íŒŒì‹± ì‹œë„ ì‹¤íŒ¨")
            return []
            
        except Exception as e:
            logger.error(f"[DEBUG]: âŒ ë¶€ë¶„ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def save_directory_results(self, directory_name, results):
        """ë””ë ‰í† ë¦¬ë³„ ê²°ê³¼ ì €ì¥ (ê¹”ë”í•œ JSON í˜•ì‹ + ì›ë³¸ ì‘ë‹µ ë°±ì—…)"""
        if not results:
            return
        
        # ë””ë ‰í† ë¦¬ ê²°ê³¼ì—ì„œ JSON ë°ì´í„° ì¶”ì¶œ
        clean_data = []
        raw_responses = []
        
        for result in results:
            response_text = result.get("response", "")
            raw_responses.append({
                "directory": directory_name,
                "image_files": result.get("image_files", []),
                "raw_response": response_text,
                "processed_at": result.get("processed_at")
            })
            
            parsed_items = self.parse_gemini_response(response_text)
            clean_data.extend(parsed_items)
        
        # 1. íŒŒì‹±ëœ ë°ì´í„° ì €ì¥ (ì„±ê³µí•œ ê²½ìš°)
        if clean_data:
            output_file = self.output_dir / f"{directory_name}.json"
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(clean_data, f, ensure_ascii=False, indent=2)
                logger.info(f"  ğŸ’¾ íŒŒì‹± ë°ì´í„° ì €ì¥: {output_file.name} ({len(clean_data)}ê°œ í•­ëª©)")
            except Exception as e:
                logger.error(f"  âŒ íŒŒì‹± ë°ì´í„° ì €ì¥ ì‹¤íŒ¨ {directory_name}: {str(e)}")
        
        # 2. ì›ë³¸ ì‘ë‹µ ì €ì¥ (í•­ìƒ ì €ì¥)
        raw_output_file = self.output_dir / f"{directory_name}_raw_response.json"
        try:
            with open(raw_output_file, 'w', encoding='utf-8') as f:
                json.dump(raw_responses, f, ensure_ascii=False, indent=2)
            logger.info(f"  ğŸ’¾ ì›ë³¸ ì‘ë‹µ ì €ì¥: {raw_output_file.name}")
        except Exception as e:
            logger.error(f"  âŒ ì›ë³¸ ì‘ë‹µ ì €ì¥ ì‹¤íŒ¨ {directory_name}: {str(e)}")
        
        # íŒŒì‹±ëœ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ ì•Œë¦¼
        if not clean_data:
            logger.warning(f"  âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨í–ˆì§€ë§Œ ì›ë³¸ ì‘ë‹µì€ ì €ì¥ë¨: {directory_name}")
            logger.info(f"  ğŸ“ ì›ë³¸ ì‘ë‹µ í™•ì¸: {raw_output_file.name}")
    
    def analyze_dataset_statistics(self, all_clean_data):
        """ë°ì´í„°ì…‹ í†µê³„ ë¶„ì„ (ë‹µì•ˆì§€ ê¸°ë°˜ ë‹µì•ˆ í¬í•¨)"""
        stats = {
            "total_items": len(all_clean_data),
            "problems": 0,
            "concepts": 0,
            "problems_with_answers": 0,
            "problems_without_answers": 0,
            "problems_with_answer_key": 0,  # ë‹µì•ˆì§€ì—ì„œ ê°€ì ¸ì˜¨ ë‹µì•ˆ
            "problems_with_inline_answer": 0,  # ë¬¸ì œì— ì§ì ‘ í‘œì‹œëœ ë‹µì•ˆ
            "problems_with_detailed_explanation": 0,  # ìƒì„¸í•œ í•´ì„¤ì´ ìˆëŠ” ë¬¸ì œ
            "problems_with_basic_explanation": 0,  # ê¸°ë³¸ì ì¸ í•´ì„¤ë§Œ ìˆëŠ” ë¬¸ì œ
            "answer_availability_rate": 0.0
        }
        
        for item in all_clean_data:
            if isinstance(item, dict):
                # ë¬¸ì œ ìœ í˜• ë¶„ë¥˜
                if item.get("problem_type") and "ê°ê´€ì‹" in str(item.get("problem_type", "")):
                    stats["problems"] += 1
                    
                    # ë‹µì•ˆ ìœ ë¬´ í™•ì¸
                    answer = item.get("answer", {})
                    if answer.get("answer_available") is True or (
                        answer.get("correct_option") and 
                        answer.get("correct_option") not in ["unknown", "null", "", None]
                    ):
                        stats["problems_with_answers"] += 1
                        
                        # ë‹µì•ˆ ì¶œì²˜ êµ¬ë¶„
                        explanation = str(answer.get("explanation", ""))
                        if "ë‹µì•ˆì§€" in explanation or "answer key" in explanation.lower():
                            stats["problems_with_answer_key"] += 1
                        else:
                            stats["problems_with_inline_answer"] += 1
                        
                        # í•´ì„¤ì˜ ì§ˆ í‰ê°€
                        if ("ì¶”ë¡  ê³¼ì •" in explanation or "ë¶„ì„" in explanation or 
                            "í•´ì„¤:" in explanation or len(explanation) > 50):
                            stats["problems_with_detailed_explanation"] += 1
                        else:
                            stats["problems_with_basic_explanation"] += 1
                    else:
                        stats["problems_without_answers"] += 1
                
                elif item.get("messages"):  # ê°œë… ì„¤ëª… ìœ í˜•
                    stats["concepts"] += 1
        
        # ë‹µì•ˆ ê°€ìš©ì„± ë¹„ìœ¨ ê³„ì‚°
        if stats["problems"] > 0:
            stats["answer_availability_rate"] = (stats["problems_with_answers"] / stats["problems"]) * 100
        
        return stats

    def save_final_results(self, all_results):
        """ìµœì¢… ê²°ê³¼ ì €ì¥ (ê¹”ë”í•œ JSON í˜•ì‹)"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ëª¨ë“  ë””ë ‰í† ë¦¬ ê²°ê³¼ì—ì„œ JSON ë°ì´í„° ì¶”ì¶œ
        all_clean_data = []
        
        for result in all_results:
            response_text = result.get("response", "")
            parsed_items = self.parse_gemini_response(response_text)
            all_clean_data.extend(parsed_items)
        
        # ì „ì²´ ê²°ê³¼ ì €ì¥
        final_output = self.output_dir / f"all_dataset_{timestamp}.json"
        
        try:
            with open(final_output, 'w', encoding='utf-8') as f:
                json.dump(all_clean_data, f, ensure_ascii=False, indent=2)
            
            # JSONL í˜•ì‹ìœ¼ë¡œë„ ì €ì¥ (LLM íŒŒì¸íŠœë‹ìš©)
            jsonl_output = self.output_dir / f"dataset_{timestamp}.jsonl"
            with open(jsonl_output, 'w', encoding='utf-8') as f:
                for item in all_clean_data:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')
            
            # ë°ì´í„°ì…‹ í†µê³„ ë¶„ì„
            dataset_stats = self.analyze_dataset_statistics(all_clean_data)
            
            # ìš”ì•½ ì •ë³´ ìƒì„±
            parsed_files = [str(f) for f in self.output_dir.glob("Chapter_*.json")] + [str(f) for f in self.output_dir.glob("*_CSAT_EXAM.json")]
            raw_files = [str(f) for f in self.output_dir.glob("*_raw_response.json")]
            
            summary = {
                "total_directories": len(set(r["directory"] for r in all_results)),
                "total_processed": len(all_results),
                "total_items": len(all_clean_data),
                "total_images": sum(len(r["image_files"]) for r in all_results),
                "dataset_statistics": dataset_stats,
                "processing_completed_at": datetime.now().isoformat(),
                "output_files": {
                    "json_file": str(final_output),
                    "jsonl_file": str(jsonl_output),
                    "parsed_data_files": parsed_files,
                    "raw_response_files": raw_files
                }
            }
            
            summary_file = self.output_dir / f"processing_summary_{timestamp}.json"
            with open(summary_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            
            logger.info(f"\n{'='*70}")
            logger.info(f"ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
            logger.info(f"{'='*70}")
            logger.info(f"ğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
            logger.info(f"  - ë””ë ‰í† ë¦¬: {summary['total_directories']}ê°œ")
            logger.info(f"  - ì²˜ë¦¬ ì™„ë£Œ: {summary['total_processed']}ê°œ")
            logger.info(f"  - ë°ì´í„° í•­ëª©: {summary['total_items']}ê°œ")
            logger.info(f"  - ì´ë¯¸ì§€: {summary['total_images']}ê°œ")
            logger.info(f"")
            logger.info(f"ğŸ“ˆ ë°ì´í„°ì…‹ êµ¬ì„±:")
            logger.info(f"  - ê°ê´€ì‹ ë¬¸ì œ: {dataset_stats['problems']}ê°œ")
            logger.info(f"  - ê°œë… ì„¤ëª…: {dataset_stats['concepts']}ê°œ")
            logger.info(f"")
            logger.info(f"âœ… ë‹µì•ˆ ê°€ìš©ì„±:")
            logger.info(f"  - ë‹µì•ˆ ìˆìŒ: {dataset_stats['problems_with_answers']}ê°œ")
            logger.info(f"    â”œâ”€ ë‹µì•ˆì§€ ê¸°ë°˜: {dataset_stats['problems_with_answer_key']}ê°œ")
            logger.info(f"    â””â”€ ë¬¸ì œ ë‚´ í‘œì‹œ: {dataset_stats['problems_with_inline_answer']}ê°œ")
            logger.info(f"  - ë‹µì•ˆ ì—†ìŒ: {dataset_stats['problems_without_answers']}ê°œ")
            logger.info(f"  - ë‹µì•ˆ ê°€ìš©ë¥ : {dataset_stats['answer_availability_rate']:.1f}%")
            logger.info(f"")
            logger.info(f"ğŸ“ í•´ì„¤ í’ˆì§ˆ:")
            logger.info(f"  - ìƒì„¸ í•´ì„¤: {dataset_stats['problems_with_detailed_explanation']}ê°œ")
            logger.info(f"  - ê¸°ë³¸ í•´ì„¤: {dataset_stats['problems_with_basic_explanation']}ê°œ")
            logger.info(f"")
            logger.info(f"ğŸ“ ì¶œë ¥ íŒŒì¼:")
            logger.info(f"  - ì „ì²´ JSON: {final_output}")
            logger.info(f"  - ì „ì²´ JSONL: {jsonl_output}")
            logger.info(f"  - íŒŒì‹±ëœ ê°œë³„ íŒŒì¼: {len(parsed_files)}ê°œ")
            logger.info(f"  - ì›ë³¸ ì‘ë‹µ íŒŒì¼: {len(raw_files)}ê°œ")
            logger.info(f"  - ì²˜ë¦¬ ìš”ì•½: {summary_file}")
            
        except Exception as e:
            logger.error(f"âŒ ìµœì¢… ì €ì¥ ì‹¤íŒ¨: {str(e)}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        logger.info("ğŸš€ Gemini ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘")
        
        # í™˜ê²½ë³€ìˆ˜ í™•ì¸
        if not os.getenv('GEMINI_API_KEY'):
            logger.error("âŒ GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            logger.info("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”:")
            logger.info("export GEMINI_API_KEY='your_api_key_here'")
            return
        
        # Gemini ë°ì´í„°ì…‹ ìƒì„±ê¸° ì´ˆê¸°í™” ë° ì‹¤í–‰
        creator = GeminiDatasetCreator()
        results = creator.process_all_directories()
        
        logger.info(f"ğŸŠ ì‘ì—… ì™„ë£Œ! ì´ {len(results)}ê°œì˜ ë””ë ‰í† ë¦¬ê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        logger.error(f"âŒ ì‘ì—… ì‹¤íŒ¨: {str(e)}")
        raise

if __name__ == "__main__":
    main()
